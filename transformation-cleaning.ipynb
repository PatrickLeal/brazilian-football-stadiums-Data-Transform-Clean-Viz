{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/patrickleal/transformation-cleaning?scriptVersionId=145147145\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\n\n# Import matplotlib for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-03T21:12:47.914557Z","iopub.execute_input":"2023-10-03T21:12:47.915029Z","iopub.status.idle":"2023-10-03T21:12:47.922957Z","shell.execute_reply.started":"2023-10-03T21:12:47.914999Z","shell.execute_reply":"2023-10-03T21:12:47.92149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_raw = pd.read_csv('/kaggle/input/brazilian-stadiums-dataset/brazilian-stadiums-details.csv')\nstadiums_raw = pd.read_csv('/kaggle/input/brazilian-stadiums-dataset/brazilian-stadiums.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:47.93188Z","iopub.execute_input":"2023-10-03T21:12:47.932911Z","iopub.status.idle":"2023-10-03T21:12:47.948297Z","shell.execute_reply.started":"2023-10-03T21:12:47.932875Z","shell.execute_reply":"2023-10-03T21:12:47.946905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_raw.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:47.966078Z","iopub.execute_input":"2023-10-03T21:12:47.967281Z","iopub.status.idle":"2023-10-03T21:12:47.981093Z","shell.execute_reply.started":"2023-10-03T21:12:47.967231Z","shell.execute_reply":"2023-10-03T21:12:47.980388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_raw.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:47.998166Z","iopub.execute_input":"2023-10-03T21:12:47.998781Z","iopub.status.idle":"2023-10-03T21:12:48.009601Z","shell.execute_reply.started":"2023-10-03T21:12:47.998749Z","shell.execute_reply":"2023-10-03T21:12:48.00841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Functions Used**","metadata":{}},{"cell_type":"markdown","source":"**Function to transform the Date column:**","metadata":{}},{"cell_type":"code","source":"def month_name_to_number(dataframe, col_index):\n    ''' This function transforms the complete date in Portuguese \n    and returns the equivalent in dd-mm-yyyy '''\n    \n    # col_index is the index of the columns i want\n    df = pd.DataFrame(dataframe.iloc[:, col_index]) # 1- creates a local dataframe with the column we want\n    \n    # creates a dict\n    mon_to_number = {\n    'janeiro': '01',\n    'fevereiro': '02',\n    'março': '03',\n    'abril': '04',\n    'maio': '05',\n    'junho': '06',\n    'julho': '07',\n    'agosto': '08',\n    'setembro': '09',\n    'outubro': '10',\n    'novembro': '11',\n    'dezembro': '12'\n    }\n    \n    column_name = df.columns[0] # 2- copy the label of the column\n    \n    for mon, num in mon_to_number.items():\n        df[column_name] = df[column_name].str.replace(mon, num)                 # 3- replace the month name with the corresponding number\n        df[column_name] = df[column_name].str.replace(str.capitalize(mon), num) # 4- replace the capitalized month name with the corresponding number   \n        df[column_name] = df[column_name].str.replace(' de ', '-').str.strip()  # 5- replace ' de ' for '-'\n    \n    dataframe[column_name] = df[column_name]                                    # 6- adiciona a coluna limpa no dataframe\n    return dataframe","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-10-03T21:12:48.015184Z","iopub.execute_input":"2023-10-03T21:12:48.015643Z","iopub.status.idle":"2023-10-03T21:12:48.025975Z","shell.execute_reply.started":"2023-10-03T21:12:48.015588Z","shell.execute_reply":"2023-10-03T21:12:48.024911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Transformation**","metadata":{}},{"cell_type":"markdown","source":"## **Stadiums Dataset**","metadata":{}},{"cell_type":"code","source":"stadiums_raw.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.036762Z","iopub.execute_input":"2023-10-03T21:12:48.038125Z","iopub.status.idle":"2023-10-03T21:12:48.050056Z","shell.execute_reply.started":"2023-10-03T21:12:48.03806Z","shell.execute_reply":"2023-10-03T21:12:48.048723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **What to do?**\n\n1. Change the labels of the columns.\n1. Change the data type of the 'capacidade' column.\n1. Replace 'Gov.' with 'Governo'","metadata":{}},{"cell_type":"markdown","source":"**1) Changing the labels of the columns**","metadata":{}},{"cell_type":"code","source":"stadiums_df = stadiums_raw.copy() # create a copy os the raw dataset\n\n# renaming de columns labels\nstadiums_df.rename(columns={'Estádio': 'Stadium_Name', \n                           'Localidade': 'Locality',\n                           'Unidade federativa': 'Federative_Units',\n                           'Proprietário': 'Owner',\n                           'Capacidade': 'Capacity'}, inplace=True) \nstadiums_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.069006Z","iopub.execute_input":"2023-10-03T21:12:48.069351Z","iopub.status.idle":"2023-10-03T21:12:48.082696Z","shell.execute_reply.started":"2023-10-03T21:12:48.069321Z","shell.execute_reply":"2023-10-03T21:12:48.081699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Changing the data type of the 'capacidade':**","metadata":{}},{"cell_type":"code","source":"stadiums_df['Capacity'] = stadiums_df['Capacity'].str.replace(' ','') # remove empty space \nstadiums_df['Capacity'] = stadiums_df['Capacity'].str.replace('.','') # remove the '.'\nstadiums_df['Capacity'] = stadiums_df['Capacity'].astype(int)         # change to int ","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.086699Z","iopub.execute_input":"2023-10-03T21:12:48.087519Z","iopub.status.idle":"2023-10-03T21:12:48.098373Z","shell.execute_reply.started":"2023-10-03T21:12:48.087487Z","shell.execute_reply":"2023-10-03T21:12:48.097081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.115778Z","iopub.execute_input":"2023-10-03T21:12:48.116305Z","iopub.status.idle":"2023-10-03T21:12:48.126183Z","shell.execute_reply.started":"2023-10-03T21:12:48.116276Z","shell.execute_reply":"2023-10-03T21:12:48.12529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Replace 'Gov.' with 'Governo'**","metadata":{}},{"cell_type":"code","source":"stadiums_df['Owner'] = stadiums_df['Owner'].str.replace('Gov.', 'Governo').str.strip()\nstadiums_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.184259Z","iopub.execute_input":"2023-10-03T21:12:48.185017Z","iopub.status.idle":"2023-10-03T21:12:48.195945Z","shell.execute_reply.started":"2023-10-03T21:12:48.184985Z","shell.execute_reply":"2023-10-03T21:12:48.195171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.203916Z","iopub.execute_input":"2023-10-03T21:12:48.20421Z","iopub.status.idle":"2023-10-03T21:12:48.2149Z","shell.execute_reply.started":"2023-10-03T21:12:48.204186Z","shell.execute_reply":"2023-10-03T21:12:48.213959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stadium Details Dataset**","metadata":{}},{"cell_type":"code","source":"stadium_details_raw.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.22498Z","iopub.execute_input":"2023-10-03T21:12:48.225745Z","iopub.status.idle":"2023-10-03T21:12:48.236006Z","shell.execute_reply.started":"2023-10-03T21:12:48.225715Z","shell.execute_reply":"2023-10-03T21:12:48.235106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **What to do?**\n\n1. Change the column labels.\n1. Transform the Date columns.\n1. Transform the 'Publico Recorde' column.\n1. Clean 'Stadium_Name'\n1. Clean 'Official_Name'\n1. Clean 'Nicknames'\n","metadata":{}},{"cell_type":"code","source":"details_stadium_df = stadium_details_raw.copy() # creating a copy of the raw dataset\ndetails_stadium_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.257859Z","iopub.execute_input":"2023-10-03T21:12:48.258672Z","iopub.status.idle":"2023-10-03T21:12:48.272988Z","shell.execute_reply.started":"2023-10-03T21:12:48.258638Z","shell.execute_reply":"2023-10-03T21:12:48.27212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1) Renaming the Columns Labels**","metadata":{}},{"cell_type":"code","source":"# choosing the new labels\nnew_labels = {'Estadio': 'Stadium_Name',\n              'link': 'Wiki_Page_Link',\n              'Nome Oficial': 'Official_Name',\n              'Apelido': 'Nicknames',\n              'Data Inauguracao': 'Opening_Date',\n              'Público recorde': 'Record_Attendance',\n              'Data recorde': 'Record_Date',\n              'Partida com mais público': 'Match_with_the_highest_attendance'}\n\n# renaming the columns\ndetails_stadium_df.rename(columns=new_labels, inplace=True) \ndetails_stadium_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.289602Z","iopub.execute_input":"2023-10-03T21:12:48.289952Z","iopub.status.idle":"2023-10-03T21:12:48.305805Z","shell.execute_reply.started":"2023-10-03T21:12:48.289925Z","shell.execute_reply":"2023-10-03T21:12:48.30469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Transforming the columns 'Date'**","metadata":{}},{"cell_type":"code","source":"details_stadium_df[['Opening_Date', 'Record_Date']].head(15)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.320461Z","iopub.execute_input":"2023-10-03T21:12:48.320824Z","iopub.status.idle":"2023-10-03T21:12:48.331834Z","shell.execute_reply.started":"2023-10-03T21:12:48.320795Z","shell.execute_reply":"2023-10-03T21:12:48.330756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a df with the column 'Opening_Date'\n# 1- removing all '()' and everything inside\nOp_date_df = pd.DataFrame(details_stadium_df['Opening_Date'].str.replace(r'\\([^)]*\\)', '', regex=True))   \n\n# 2- removing all '[]' and everything inside\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)  \n\n# 3- removing all '\\n' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'\\n.*', '', regex=True)              \n\n# 4- removing all 'e reinauguração' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'e reinauguração.*', '', regex=True) \n\n# 5- removing all 'Reinauguração' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'Reinauguração.*', '', regex=True)\n\n# 6- removing all 'Original:'\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('Original:', '')   \n\n# 7- removing all 'Inauguração 1º' and replacing for '01'\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('Inauguração 1º', '01')   \n\n# 8- removing all '— ' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'— .*', '', regex=True)     \n\n# 9- removing all '1º' and replacing for '01'\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('1º', '01')                   \n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.337744Z","iopub.execute_input":"2023-10-03T21:12:48.338107Z","iopub.status.idle":"2023-10-03T21:12:48.350927Z","shell.execute_reply.started":"2023-10-03T21:12:48.338079Z","shell.execute_reply":"2023-10-03T21:12:48.349962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I know there's probably a better way to do this, but I couldn't figure it out.\n\nI had to use chatGPT  for some Regex.","metadata":{}},{"cell_type":"markdown","source":"Now I need to obtain only the first occurrence where the complete date appears.\n\nI know by reading the wiki page that this is the original opening date.","metadata":{}},{"cell_type":"code","source":"concatenated_lines = []                        # 1- the list that will store the cleaned lines\n\nfor i in range(len(Op_date_df)):\n    try:\n\n        line = []                              # 2- the list  of the current line in the loop\n        \n                                               # 3- in this block i get the splited elements of the current line\n        for ele in Op_date_df.iloc[i]:\n            value = ele.split()\n            line.append(value)\n            break\n\n        line = line[0][:5]                     # 4- save only the first 5 elements \n        concat_line = ' '.join(line)           # 5- Receives the line with the first 5 elements of each line concatenated\n        concatenated_lines.append(concat_line) # 6- append the current line in the lists with the lines concatenated\n    except Exception as error:\n        concatenated_lines.append(np.nan)      # 7- append a nan if an error occurs\n    \nclean_Date = pd.Series(concatenated_lines)     # 8- create a Series with all cleaned lines","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.355837Z","iopub.execute_input":"2023-10-03T21:12:48.356151Z","iopub.status.idle":"2023-10-03T21:12:48.372099Z","shell.execute_reply.started":"2023-10-03T21:12:48.356125Z","shell.execute_reply":"2023-10-03T21:12:48.370873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Op_date_df['clean_OP_Date'] = clean_Date\nOp_date_df['clean_OP_Date'].head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.374192Z","iopub.execute_input":"2023-10-03T21:12:48.374641Z","iopub.status.idle":"2023-10-03T21:12:48.389829Z","shell.execute_reply.started":"2023-10-03T21:12:48.374573Z","shell.execute_reply":"2023-10-03T21:12:48.388708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking inconsistencies","metadata":{}},{"cell_type":"code","source":"Op_date_df[['Opening_Date', 'clean_OP_Date']].loc[124:133]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.402649Z","iopub.execute_input":"2023-10-03T21:12:48.403529Z","iopub.status.idle":"2023-10-03T21:12:48.415036Z","shell.execute_reply.started":"2023-10-03T21:12:48.403485Z","shell.execute_reply":"2023-10-03T21:12:48.413909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fixing two more lines","metadata":{}},{"cell_type":"code","source":"# replacing with the correct date\nOp_date_df['clean_OP_Date'] = Op_date_df['clean_OP_Date'].str.replace('198427', '1984')\nOp_date_df['clean_OP_Date'] = Op_date_df['clean_OP_Date'].str.replace('19403', '1940')\nOp_date_df.loc[124:133]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.432325Z","iopub.execute_input":"2023-10-03T21:12:48.43336Z","iopub.status.idle":"2023-10-03T21:12:48.444229Z","shell.execute_reply.started":"2023-10-03T21:12:48.433323Z","shell.execute_reply":"2023-10-03T21:12:48.443483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is correct, time to add the new clean opening column to the main dataframe","metadata":{}},{"cell_type":"code","source":"details_stadium_df['opening_date_cleaned'] = Op_date_df['clean_OP_Date']\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.461448Z","iopub.execute_input":"2023-10-03T21:12:48.46251Z","iopub.status.idle":"2023-10-03T21:12:48.4681Z","shell.execute_reply.started":"2023-10-03T21:12:48.462463Z","shell.execute_reply":"2023-10-03T21:12:48.467312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df[['Opening_Date', 'opening_date_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.530038Z","iopub.execute_input":"2023-10-03T21:12:48.530796Z","iopub.status.idle":"2023-10-03T21:12:48.541591Z","shell.execute_reply.started":"2023-10-03T21:12:48.530765Z","shell.execute_reply":"2023-10-03T21:12:48.540352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df.iloc[:, 8].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.548342Z","iopub.execute_input":"2023-10-03T21:12:48.548716Z","iopub.status.idle":"2023-10-03T21:12:48.557302Z","shell.execute_reply.started":"2023-10-03T21:12:48.548687Z","shell.execute_reply":"2023-10-03T21:12:48.555153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the function to tranform the dates\nmonth_name_to_number(details_stadium_df, 8)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.582481Z","iopub.execute_input":"2023-10-03T21:12:48.583108Z","iopub.status.idle":"2023-10-03T21:12:48.658042Z","shell.execute_reply.started":"2023-10-03T21:12:48.583077Z","shell.execute_reply":"2023-10-03T21:12:48.657285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df[['Opening_Date','Record_Date', 'opening_date_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.65963Z","iopub.execute_input":"2023-10-03T21:12:48.660165Z","iopub.status.idle":"2023-10-03T21:12:48.674692Z","shell.execute_reply.started":"2023-10-03T21:12:48.660129Z","shell.execute_reply":"2023-10-03T21:12:48.673964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Time to do the same with 'Record_Date' column**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.676206Z","iopub.execute_input":"2023-10-03T21:12:48.676576Z","iopub.status.idle":"2023-10-03T21:12:48.680841Z","shell.execute_reply.started":"2023-10-03T21:12:48.67655Z","shell.execute_reply":"2023-10-03T21:12:48.679909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a df with the 'Record_Date' column\nrec_date_df = pd.DataFrame(details_stadium_df['Record_Date'])\nrec_date_df['clean_rec_date'] = rec_date_df['Record_Date'].str.replace(r'\\([^)]*\\)', '', regex=True)   # 1- removing all '()' and everything inside\n\n# Looking at the stadium's Wiki page, both dates had the same record attendance,\n# so I decided to save the more recent one, which is November 2, 2010\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace('29 de maio[3] e ', '')\n\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace(r'\\[[^\\]]*\\]', '', regex=True) # 2- removing all '[]' and everything inside\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace('1º', '01')                    # 3- removing all '1º' and replacing for '01'","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.682728Z","iopub.execute_input":"2023-10-03T21:12:48.683014Z","iopub.status.idle":"2023-10-03T21:12:48.697398Z","shell.execute_reply.started":"2023-10-03T21:12:48.682989Z","shell.execute_reply":"2023-10-03T21:12:48.696585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df['record_date_cleaned'] = rec_date_df['clean_rec_date']\ndetails_stadium_df[['Record_Date', 'record_date_cleaned']]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.698437Z","iopub.execute_input":"2023-10-03T21:12:48.699233Z","iopub.status.idle":"2023-10-03T21:12:48.729801Z","shell.execute_reply.started":"2023-10-03T21:12:48.699205Z","shell.execute_reply":"2023-10-03T21:12:48.728604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using the function to clean the date\nmonth_name_to_number(details_stadium_df, 9)\n\ndetails_stadium_df['record_date_cleaned'] = details_stadium_df['record_date_cleaned'].str.replace(' ', '-').str.replace('/', '-')\ndetails_stadium_df[['Record_Date','record_date_cleaned']].head(20)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.731301Z","iopub.execute_input":"2023-10-03T21:12:48.731805Z","iopub.status.idle":"2023-10-03T21:12:48.77295Z","shell.execute_reply.started":"2023-10-03T21:12:48.731776Z","shell.execute_reply":"2023-10-03T21:12:48.771712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Transforming the 'Record_Attendance' column**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.774313Z","iopub.execute_input":"2023-10-03T21:12:48.774581Z","iopub.status.idle":"2023-10-03T21:12:48.784022Z","shell.execute_reply.started":"2023-10-03T21:12:48.774557Z","shell.execute_reply":"2023-10-03T21:12:48.783018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a df with the copy of the 'Record_Attendance' column\nrec_attendance_df = pd.DataFrame(details_stadium_df['Record_Attendance'])\n\n# removing some words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['Record_Attendance'].str.replace('presentes', '')\\\n                                                                                  .str.replace('pagantes', '_').str.strip() # replaces a word for '_'\n\n# removing the words 'pessoas'\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('pessoas2', '')\\\n                                                                                     .str.replace('Pessoas', '')\\\n                                                                                     .str.replace('pessoas', ' ')\n\n#removing some more words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('torcedores', '')\\\n                                                                                     .str.replace('espectadores', '')\\\n                                                                                     .str.replace('lugares', '')\n# removing [] and everything inside\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)\n\n# removing more words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('(não oficial)', '')\\\n                                                                                     .str.replace('(de acordo com a CBF)', '')\\\n                                                                                     .str.replace('(público total)', '')\n\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('.', '') # remove dots\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('  ', '+') # replace double spaces for '+'\n\n# creates a dictionary with words and symbols i will remove or replace for oanother symbols\nreplace = {'pags': '', 'mil': '000', 'Mil':'', '\\n': '-', 'e': '', ',': '', '\\xa0': ''}\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].replace(replace, regex=True) # uses the dict created\n\n# replaces the () for '-'\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(r'[()]', '-', regex=True).str.strip()\n\n# replace some more symbols\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(' ', '')\\\n                                                                                    .str.replace('+-', '-')\\\n                                                                                    .str.replace('_', '-')\\\n                                                                                    .str.replace('--', '-')\\\n                                                                                    .str.replace('+', '-')\\\n                                                                                    .str.replace('-', ' ')\\\n                                                                                    .str.strip()\n\n# gets only the max number of each line \nrec_attendance_df['clean_rec_attendance'] = [max(linha.split()) if isinstance(linha, str) else np.nan\n                                             for linha in rec_attendance_df['clean_rec_attendance']]\n ","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.785287Z","iopub.execute_input":"2023-10-03T21:12:48.785723Z","iopub.status.idle":"2023-10-03T21:12:48.810958Z","shell.execute_reply.started":"2023-10-03T21:12:48.785681Z","shell.execute_reply":"2023-10-03T21:12:48.809987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add the cleaned column to the main df\ndetails_stadium_df['record_attendance_cleaned'] = rec_attendance_df['clean_rec_attendance']\ndetails_stadium_df[['Record_Attendance', 'record_attendance_cleaned']].head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.812945Z","iopub.execute_input":"2023-10-03T21:12:48.813811Z","iopub.status.idle":"2023-10-03T21:12:48.838092Z","shell.execute_reply.started":"2023-10-03T21:12:48.813773Z","shell.execute_reply":"2023-10-03T21:12:48.83689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4) Cleaning 'Stadium_Name' column**","metadata":{}},{"cell_type":"code","source":"# creates a new column in the main df and remove the word 'Sisbrace' and everything that comes after\ndetails_stadium_df['stadium_name_cleaned'] = details_stadium_df['Stadium_Name'].str.replace(r'Sisbrace.*', '', regex=True)\n\n# remove the [] and everything inside\ndetails_stadium_df['stadium_name_cleaned'] = details_stadium_df['stadium_name_cleaned'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)\n\n# remove the () in this particular line\ndetails_stadium_df['stadium_name_cleaned'][27] = details_stadium_df['stadium_name_cleaned'][27].replace('(Manduzão)', 'Manduzão')\n\ndetails_stadium_df[['Stadium_Name', 'stadium_name_cleaned']].head(15)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.839407Z","iopub.execute_input":"2023-10-03T21:12:48.839801Z","iopub.status.idle":"2023-10-03T21:12:48.858252Z","shell.execute_reply.started":"2023-10-03T21:12:48.839772Z","shell.execute_reply":"2023-10-03T21:12:48.857349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5) Cleaning 'Official_Name' column**","metadata":{}},{"cell_type":"code","source":"# creates a new column in the main df and remove the word 'Sisbrace' and everything that comes after\ndetails_stadium_df['official_name_cleaned'] = details_stadium_df['Official_Name'].str.replace(r'Sisbrace.*', '', regex=True)\n\n# remove the [] and everything inside\ndetails_stadium_df['official_name_cleaned'] = details_stadium_df['official_name_cleaned'].str.replace(r'\\[[^\\]]*\\]', '', regex=True).str.strip()\n\ndetails_stadium_df[['Official_Name', 'official_name_cleaned']].head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.859375Z","iopub.execute_input":"2023-10-03T21:12:48.859695Z","iopub.status.idle":"2023-10-03T21:12:48.874376Z","shell.execute_reply.started":"2023-10-03T21:12:48.859667Z","shell.execute_reply":"2023-10-03T21:12:48.873688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6) Cleaning 'Nicknames' column**","metadata":{}},{"cell_type":"code","source":"# creates a new column in the main df and remove the word 'Sisbrace' and everything that comes after\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['Nicknames'].str.replace(r'Sisbrace.*', '', regex=True)\n\n# clean this particular line\ndetails_stadium_df['nicknames_cleaned'][18] = details_stadium_df['nicknames_cleaned'][18].replace('Ilha', ' Ilha, ')\\\n                                                                                         .replace(',  ', ' ').strip()\n\n# remove the [] and everything inside\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['nicknames_cleaned'].str.replace(r'\\[[^\\]]*\\]', ' ', regex=True).str.strip()\n\n# replace the '\\n' for an empty space\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['nicknames_cleaned'].str.replace('\\n', ' ')\n\n# add an empty space before all capitalized word\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['nicknames_cleaned'].str.replace(r'([A-Z])([a-z])', r' \\1\\2', regex=True).str.strip()\n\n# remove some symbols\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['nicknames_cleaned'].str.replace('\"', '').str.replace('.', '').str.strip()\ndetails_stadium_df['nicknames_cleaned'] = details_stadium_df['nicknames_cleaned'].str.replace('-', ' ').str.replace('/', ' ').str.replace('  ', ' ')\n\n# clean this particular line\ndetails_stadium_df['nicknames_cleaned'][40] = details_stadium_df['nicknames_cleaned'][40].replace('BelmiroA','Belmiro A')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.875392Z","iopub.execute_input":"2023-10-03T21:12:48.876336Z","iopub.status.idle":"2023-10-03T21:12:48.894461Z","shell.execute_reply.started":"2023-10-03T21:12:48.876308Z","shell.execute_reply":"2023-10-03T21:12:48.893478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df[['Nicknames', 'nicknames_cleaned']].head(20)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:16:46.352818Z","iopub.execute_input":"2023-10-03T21:16:46.353164Z","iopub.status.idle":"2023-10-03T21:16:46.36527Z","shell.execute_reply.started":"2023-10-03T21:16:46.353138Z","shell.execute_reply":"2023-10-03T21:16:46.364146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some stadiums have more than one nickname, they should be separated by commas but they are not, so I think this column won't be very useful for further analysis.","metadata":{}},{"cell_type":"code","source":"wanted_columns = ['stadium_name_cleaned', 'official_name_cleaned', 'nicknames_cleaned', 'opening_date_cleaned',\n                 'record_attendance_cleaned', 'record_date_cleaned', 'Match_with_the_highest_attendance']\n\n#create a new df with only the transformed columns\nstadium_details_cleaned = details_stadium_df[wanted_columns]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.941418Z","iopub.execute_input":"2023-10-03T21:12:48.941999Z","iopub.status.idle":"2023-10-03T21:12:48.964065Z","shell.execute_reply.started":"2023-10-03T21:12:48.94197Z","shell.execute_reply":"2023-10-03T21:12:48.963177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The new df:","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.965812Z","iopub.execute_input":"2023-10-03T21:12:48.966317Z","iopub.status.idle":"2023-10-03T21:12:48.989887Z","shell.execute_reply.started":"2023-10-03T21:12:48.96628Z","shell.execute_reply":"2023-10-03T21:12:48.989095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"## **Stadiums Dataset**","metadata":{}},{"cell_type":"code","source":"stadiums_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:48.990775Z","iopub.execute_input":"2023-10-03T21:12:48.991189Z","iopub.status.idle":"2023-10-03T21:12:49.010414Z","shell.execute_reply.started":"2023-10-03T21:12:48.991164Z","shell.execute_reply":"2023-10-03T21:12:49.009282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like there is no missing values in this dataset and the types are correct","metadata":{}},{"cell_type":"code","source":"stadiums_df[stadiums_df.duplicated() == True]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.012043Z","iopub.execute_input":"2023-10-03T21:12:49.012447Z","iopub.status.idle":"2023-10-03T21:12:49.023285Z","shell.execute_reply.started":"2023-10-03T21:12:49.012409Z","shell.execute_reply":"2023-10-03T21:12:49.022442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no Duplicated ","metadata":{}},{"cell_type":"markdown","source":"## **Stadium Details Dataset**","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.026052Z","iopub.execute_input":"2023-10-03T21:12:49.026958Z","iopub.status.idle":"2023-10-03T21:12:49.042655Z","shell.execute_reply.started":"2023-10-03T21:12:49.026925Z","shell.execute_reply":"2023-10-03T21:12:49.041474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What to do?**\n\n1. Remove the missing dates\n1. Convert date columns to the 'date' type\n1. Convert the 'record_attendance_cleaned' column to int","metadata":{}},{"cell_type":"markdown","source":"**1) Remove the missing dates**","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned[stadium_details_cleaned['opening_date_cleaned'].isna()]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.043992Z","iopub.execute_input":"2023-10-03T21:12:49.044287Z","iopub.status.idle":"2023-10-03T21:12:49.058639Z","shell.execute_reply.started":"2023-10-03T21:12:49.044262Z","shell.execute_reply":"2023-10-03T21:12:49.057483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These rows have a lot more missing data.","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned = stadium_details_cleaned.dropna(subset=['opening_date_cleaned', 'record_date_cleaned'],\n                                                         ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.060038Z","iopub.execute_input":"2023-10-03T21:12:49.060339Z","iopub.status.idle":"2023-10-03T21:12:49.071985Z","shell.execute_reply.started":"2023-10-03T21:12:49.060313Z","shell.execute_reply":"2023-10-03T21:12:49.070895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Convert date columns to the 'date' type**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.073095Z","iopub.execute_input":"2023-10-03T21:12:49.073835Z","iopub.status.idle":"2023-10-03T21:12:49.086075Z","shell.execute_reply.started":"2023-10-03T21:12:49.073807Z","shell.execute_reply":"2023-10-03T21:12:49.085141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Opening Date column**","metadata":{}},{"cell_type":"code","source":"opening_date_cleaned = stadium_details_cleaned['opening_date_cleaned']\nindices = [indice for indice, elemento in enumerate(stadium_details_cleaned['opening_date_cleaned'])\n           if len(elemento) <= 4]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.087535Z","iopub.execute_input":"2023-10-03T21:12:49.08853Z","iopub.status.idle":"2023-10-03T21:12:49.0998Z","shell.execute_reply.started":"2023-10-03T21:12:49.08849Z","shell.execute_reply":"2023-10-03T21:12:49.098998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_cleaned['opening_date_cleaned'][indices]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.100945Z","iopub.execute_input":"2023-10-03T21:12:49.101353Z","iopub.status.idle":"2023-10-03T21:12:49.120299Z","shell.execute_reply.started":"2023-10-03T21:12:49.101327Z","shell.execute_reply":"2023-10-03T21:12:49.119286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Four stadiums have only the year for the opening date, i will keep them and create a dummy month and day.","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned['opening_date_cleaned'] = pd.to_datetime(stadium_details_cleaned['opening_date_cleaned'], format='mixed')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.121703Z","iopub.execute_input":"2023-10-03T21:12:49.121995Z","iopub.status.idle":"2023-10-03T21:12:49.132704Z","shell.execute_reply.started":"2023-10-03T21:12:49.121971Z","shell.execute_reply":"2023-10-03T21:12:49.13187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Record Date column**","metadata":{}},{"cell_type":"markdown","source":"Only a few dates do not have the complete date, i will keep them too.","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned['record_date_cleaned'] = pd.to_datetime(stadium_details_cleaned['record_date_cleaned'], format='mixed')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.134524Z","iopub.execute_input":"2023-10-03T21:12:49.134828Z","iopub.status.idle":"2023-10-03T21:12:49.146084Z","shell.execute_reply.started":"2023-10-03T21:12:49.134802Z","shell.execute_reply":"2023-10-03T21:12:49.145049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Convert the 'record_attendance_cleaned' column to int**","metadata":{}},{"cell_type":"markdown","source":"There is only one missing value in the record_attendance_cleaned column, so i will drop it","metadata":{}},{"cell_type":"code","source":"stadium_details_cleaned = stadium_details_cleaned.dropna(subset='record_attendance_cleaned')\nstadium_details_cleaned['record_attendance_cleaned'] = pd.to_numeric(stadium_details_cleaned['record_attendance_cleaned'], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:12:49.147438Z","iopub.execute_input":"2023-10-03T21:12:49.148237Z","iopub.status.idle":"2023-10-03T21:12:49.1625Z","shell.execute_reply.started":"2023-10-03T21:12:49.148208Z","shell.execute_reply":"2023-10-03T21:12:49.161638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_cleaned.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:28:33.997815Z","iopub.execute_input":"2023-10-03T21:28:33.998169Z","iopub.status.idle":"2023-10-03T21:28:34.015567Z","shell.execute_reply.started":"2023-10-03T21:28:33.998143Z","shell.execute_reply":"2023-10-03T21:28:34.014429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the types are correct","metadata":{}},{"cell_type":"code","source":"stadiums_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:29:47.967459Z","iopub.execute_input":"2023-10-03T21:29:47.967925Z","iopub.status.idle":"2023-10-03T21:29:47.980707Z","shell.execute_reply.started":"2023-10-03T21:29:47.967884Z","shell.execute_reply":"2023-10-03T21:29:47.979703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing the '_cleaned' in the columns names\nstadium_details_cleaned.columns = stadium_details_cleaned.columns.str.replace('_cleaned', '')\nstadium_details_cleaned.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:31:37.362597Z","iopub.execute_input":"2023-10-03T21:31:37.363182Z","iopub.status.idle":"2023-10-03T21:31:37.373414Z","shell.execute_reply.started":"2023-10-03T21:31:37.363137Z","shell.execute_reply":"2023-10-03T21:31:37.372235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the cleaned dfs to csv","metadata":{}},{"cell_type":"code","source":"stadiums_df.to_csv('/kaggle/working/stadiums.csv', index=False)\nstadium_details_cleaned.to_csv('/kaggle/working/stadium_details.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T21:38:05.214697Z","iopub.execute_input":"2023-10-03T21:38:05.215047Z","iopub.status.idle":"2023-10-03T21:38:05.229189Z","shell.execute_reply.started":"2023-10-03T21:38:05.215021Z","shell.execute_reply":"2023-10-03T21:38:05.22787Z"},"trusted":true},"execution_count":null,"outputs":[]}]}