{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/patrickleal/transformation-cleaning-viz?scriptVersionId=145019740\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Import matplotlib for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T20:19:17.952417Z","iopub.execute_input":"2023-10-02T20:19:17.953592Z","iopub.status.idle":"2023-10-02T20:19:17.961278Z","shell.execute_reply.started":"2023-10-02T20:19:17.953517Z","shell.execute_reply":"2023-10-02T20:19:17.960122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_raw = pd.read_csv('/kaggle/input/brazilian-stadiums-dataset/brazilian-stadiums-details.csv')\nstadiums_raw = pd.read_csv('/kaggle/input/brazilian-stadiums-dataset/brazilian-stadiums.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:17.96814Z","iopub.execute_input":"2023-10-02T20:19:17.969611Z","iopub.status.idle":"2023-10-02T20:19:17.988523Z","shell.execute_reply.started":"2023-10-02T20:19:17.969563Z","shell.execute_reply":"2023-10-02T20:19:17.98749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadium_details_raw.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:17.99522Z","iopub.execute_input":"2023-10-02T20:19:17.996135Z","iopub.status.idle":"2023-10-02T20:19:18.013952Z","shell.execute_reply.started":"2023-10-02T20:19:17.996077Z","shell.execute_reply":"2023-10-02T20:19:18.012493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_raw.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.022249Z","iopub.execute_input":"2023-10-02T20:19:18.023559Z","iopub.status.idle":"2023-10-02T20:19:18.035834Z","shell.execute_reply.started":"2023-10-02T20:19:18.023488Z","shell.execute_reply":"2023-10-02T20:19:18.034686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Functions Used**","metadata":{}},{"cell_type":"markdown","source":"**Function to transform the Date column:**","metadata":{}},{"cell_type":"code","source":"def month_name_to_number(dataframe, col_index):\n    ''' This function transforms the complete date in Portuguese \n    and returns the equivalent in dd-mm-yyyy '''\n    \n    # col_index is the index of the columns i want\n    df = pd.DataFrame(dataframe.iloc[:, col_index]) # 1- creates a local dataframe with the column we want\n    \n    # creates a dict\n    mon_to_number = {\n    'janeiro': '01',\n    'fevereiro': '02',\n    'março': '03',\n    'abril': '04',\n    'maio': '05',\n    'junho': '06',\n    'julho': '07',\n    'agosto': '08',\n    'setembro': '09',\n    'outubro': '10',\n    'novembro': '11',\n    'dezembro': '12'\n    }\n    \n    column_name = df.columns[0] # 2- copy the label of the column\n    \n    for mon, num in mon_to_number.items():\n        df[column_name] = df[column_name].str.replace(mon, num)                 # 3- replace the month name with the corresponding number\n        df[column_name] = df[column_name].str.replace(str.capitalize(mon), num) # 4- replace the capitalized month name with the corresponding number   \n        df[column_name] = df[column_name].str.replace(' de ', '-').str.strip()  # 5- replace ' de ' for '-'\n    \n    dataframe[column_name] = df[column_name]                                    # 6- adiciona a coluna limpa no dataframe\n    return dataframe","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-10-02T20:19:18.038115Z","iopub.execute_input":"2023-10-02T20:19:18.038948Z","iopub.status.idle":"2023-10-02T20:19:18.052749Z","shell.execute_reply.started":"2023-10-02T20:19:18.038906Z","shell.execute_reply":"2023-10-02T20:19:18.051425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Transformation**","metadata":{}},{"cell_type":"markdown","source":"## **Stadiums Dataset**","metadata":{}},{"cell_type":"code","source":"stadiums_raw.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.0542Z","iopub.execute_input":"2023-10-02T20:19:18.054479Z","iopub.status.idle":"2023-10-02T20:19:18.080085Z","shell.execute_reply.started":"2023-10-02T20:19:18.054455Z","shell.execute_reply":"2023-10-02T20:19:18.078907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **What to do?**\n\n1. Change the labels of the columns.\n1. Change the data type of the 'capacidade' column.\n1. Replace 'Gov.' with 'Governo'","metadata":{}},{"cell_type":"markdown","source":"**1) Changing the labels of the columns**","metadata":{}},{"cell_type":"code","source":"stadiums_df = stadiums_raw.copy() # create a copy os the raw dataset\n\n# renaming de columns labels\nstadiums_df.rename(columns={'Estádio': 'Stadium_Name', \n                           'Localidade': 'Locality',\n                           'Unidade federativa': 'Federative_Units',\n                           'Proprietário': 'Owner',\n                           'Capacidade': 'Capacity'}, inplace=True) \nstadiums_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.083627Z","iopub.execute_input":"2023-10-02T20:19:18.084218Z","iopub.status.idle":"2023-10-02T20:19:18.103028Z","shell.execute_reply.started":"2023-10-02T20:19:18.084186Z","shell.execute_reply":"2023-10-02T20:19:18.101835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Changing the data type of the 'capacidade':**","metadata":{}},{"cell_type":"code","source":"stadiums_df['Capacity'] = stadiums_df['Capacity'].str.replace(' ','') # remove empty space \nstadiums_df['Capacity'] = stadiums_df['Capacity'].str.replace('.','') # remove the '.'\nstadiums_df['Capacity'] = stadiums_df['Capacity'].astype(int)         # change to int ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.127557Z","iopub.execute_input":"2023-10-02T20:19:18.128274Z","iopub.status.idle":"2023-10-02T20:19:18.138498Z","shell.execute_reply.started":"2023-10-02T20:19:18.128229Z","shell.execute_reply":"2023-10-02T20:19:18.137019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.149285Z","iopub.execute_input":"2023-10-02T20:19:18.149927Z","iopub.status.idle":"2023-10-02T20:19:18.16256Z","shell.execute_reply.started":"2023-10-02T20:19:18.149893Z","shell.execute_reply":"2023-10-02T20:19:18.161432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Replace 'Gov.' with 'Governo'**","metadata":{}},{"cell_type":"code","source":"stadiums_df['Owner'] = stadiums_df['Owner'].str.replace('Gov.', 'Governo').str.strip()\nstadiums_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.196282Z","iopub.execute_input":"2023-10-02T20:19:18.196739Z","iopub.status.idle":"2023-10-02T20:19:18.212502Z","shell.execute_reply.started":"2023-10-02T20:19:18.196707Z","shell.execute_reply":"2023-10-02T20:19:18.211311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stadiums_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.214649Z","iopub.execute_input":"2023-10-02T20:19:18.215247Z","iopub.status.idle":"2023-10-02T20:19:18.236708Z","shell.execute_reply.started":"2023-10-02T20:19:18.215211Z","shell.execute_reply":"2023-10-02T20:19:18.235185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stadium Details Dataset**","metadata":{}},{"cell_type":"code","source":"stadium_details_raw.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.239317Z","iopub.execute_input":"2023-10-02T20:19:18.239678Z","iopub.status.idle":"2023-10-02T20:19:18.252325Z","shell.execute_reply.started":"2023-10-02T20:19:18.239651Z","shell.execute_reply":"2023-10-02T20:19:18.250758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **What to do?**\n\n1. Change the column labels.\n1. Transform the Date columns.\n1. Transform the 'Publico Recorde' column.\n1. Clean 'Stadium_Name'\n1. Clean 'Official_Name'\n1. Clean 'Nicknames'\n","metadata":{}},{"cell_type":"code","source":"details_stadium_df = stadium_details_raw.copy() # creating a copy of the raw dataset\ndetails_stadium_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.254315Z","iopub.execute_input":"2023-10-02T20:19:18.254742Z","iopub.status.idle":"2023-10-02T20:19:18.270739Z","shell.execute_reply.started":"2023-10-02T20:19:18.254704Z","shell.execute_reply":"2023-10-02T20:19:18.26933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1) Renaming the Columns Labels**","metadata":{}},{"cell_type":"code","source":"# choosing the new labels\nnew_labels = {'Estadio': 'Stadium_Name',\n              'link': 'Wiki_Page_Link',\n              'Nome Oficial': 'Official_Name',\n              'Apelido': 'Nicknames',\n              'Data Inauguracao': 'Opening_Date',\n              'Público recorde': 'Record_Attendance',\n              'Data recorde': 'Record_Date',\n              'Partida com mais público': 'Match_with_the_highest_attendance'}\n\n# renaming the columns\ndetails_stadium_df.rename(columns=new_labels, inplace=True) \ndetails_stadium_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.273313Z","iopub.execute_input":"2023-10-02T20:19:18.273658Z","iopub.status.idle":"2023-10-02T20:19:18.295876Z","shell.execute_reply.started":"2023-10-02T20:19:18.273631Z","shell.execute_reply":"2023-10-02T20:19:18.294669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Transforming the columns 'Date'**","metadata":{}},{"cell_type":"code","source":"details_stadium_df[['Opening_Date', 'Record_Date']].head(15)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.297437Z","iopub.execute_input":"2023-10-02T20:19:18.297949Z","iopub.status.idle":"2023-10-02T20:19:18.315404Z","shell.execute_reply.started":"2023-10-02T20:19:18.29792Z","shell.execute_reply":"2023-10-02T20:19:18.31415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a df with the column 'Opening_Date'\nOp_date_df = pd.DataFrame(details_stadium_df['Opening_Date'].str.replace(r'\\([^)]*\\)', '', regex=True))   # 1- removing all '()' and everything inside\n\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)        # 2- removing all '[]' and everything inside\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'\\n.*', '', regex=True)              # 3- removing all '\\n' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'e reinauguração.*', '', regex=True) # 4- removing all 'e reinauguração' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'Reinauguração.*', '', regex=True)   # 5- removing all 'Reinauguração' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('Original:', '')                      # 6- removing all 'Original:'\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('Inauguração 1º', '01')               # 7- removing all 'Inauguração 1º' and replacing for '01'\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace(r'— .*', '', regex=True)              # 8- removing all '— ' and everything that comes after\nOp_date_df['Opening_Date'] = Op_date_df['Opening_Date'].str.replace('1º', '01')                           # 9- removing all '1º' and replacing for '01'\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.318099Z","iopub.execute_input":"2023-10-02T20:19:18.318958Z","iopub.status.idle":"2023-10-02T20:19:18.333855Z","shell.execute_reply.started":"2023-10-02T20:19:18.318913Z","shell.execute_reply":"2023-10-02T20:19:18.332537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I know there's probably a better way to do this, but I couldn't figure it out.\n\nI had to use chatGPT  for some Regex.","metadata":{}},{"cell_type":"markdown","source":"Now I need to obtain only the first occurrence where the complete date appears.\n\nI know by reading the wiki page that this is the original opening date.","metadata":{}},{"cell_type":"code","source":"concatenated_lines = []                        # 1- the list that will store the cleaned lines\n\nfor i in range(len(Op_date_df)):\n    try:\n\n        line = []                              # 2- the list  of the current line in the loop\n        \n                                               # 3- in this block i get the splited elements of the current line\n        for ele in Op_date_df.iloc[i]:\n            value = ele.split()\n            line.append(value)\n            break\n\n        line = line[0][:5]                     # 4- save only the first 5 elements \n        concat_line = ' '.join(line)           # 5- Receives the line with the first 5 elements of each line concatenated\n        concatenated_lines.append(concat_line) # 6- append the current line in the lists with the lines concatenated\n    except Exception as error:\n        concatenated_lines.append(np.nan)      # 7- append a nan if an error occurs\n    \nclean_Date = pd.Series(concatenated_lines)     # 8- create a Series with all cleaned lines","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.335762Z","iopub.execute_input":"2023-10-02T20:19:18.336358Z","iopub.status.idle":"2023-10-02T20:19:18.363929Z","shell.execute_reply.started":"2023-10-02T20:19:18.336326Z","shell.execute_reply":"2023-10-02T20:19:18.362798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Op_date_df['clean_OP_Date'] = clean_Date\nOp_date_df['clean_OP_Date'].head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.365523Z","iopub.execute_input":"2023-10-02T20:19:18.366849Z","iopub.status.idle":"2023-10-02T20:19:18.388434Z","shell.execute_reply.started":"2023-10-02T20:19:18.366809Z","shell.execute_reply":"2023-10-02T20:19:18.387512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking inconsistencies","metadata":{}},{"cell_type":"code","source":"Op_date_df[['Opening_Date', 'clean_OP_Date']].loc[124:133]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.389878Z","iopub.execute_input":"2023-10-02T20:19:18.390946Z","iopub.status.idle":"2023-10-02T20:19:18.407613Z","shell.execute_reply.started":"2023-10-02T20:19:18.390909Z","shell.execute_reply":"2023-10-02T20:19:18.406461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fixing two more lines","metadata":{}},{"cell_type":"code","source":"# replacing with the correct date\nOp_date_df['clean_OP_Date'] = Op_date_df['clean_OP_Date'].str.replace('198427', '1984')\nOp_date_df['clean_OP_Date'] = Op_date_df['clean_OP_Date'].str.replace('19403', '1940')\nOp_date_df.loc[124:133]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.409143Z","iopub.execute_input":"2023-10-02T20:19:18.409599Z","iopub.status.idle":"2023-10-02T20:19:18.424463Z","shell.execute_reply.started":"2023-10-02T20:19:18.409571Z","shell.execute_reply":"2023-10-02T20:19:18.423552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is correct, time to add the new clean opening column to the main dataframe","metadata":{}},{"cell_type":"code","source":"details_stadium_df['opening_date_cleaned'] = Op_date_df['clean_OP_Date']\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.42576Z","iopub.execute_input":"2023-10-02T20:19:18.426514Z","iopub.status.idle":"2023-10-02T20:19:18.441869Z","shell.execute_reply.started":"2023-10-02T20:19:18.426449Z","shell.execute_reply":"2023-10-02T20:19:18.440728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df[['Opening_Date', 'opening_date_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.443977Z","iopub.execute_input":"2023-10-02T20:19:18.445272Z","iopub.status.idle":"2023-10-02T20:19:18.464408Z","shell.execute_reply.started":"2023-10-02T20:19:18.445215Z","shell.execute_reply":"2023-10-02T20:19:18.463067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df.iloc[:, 8].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.466869Z","iopub.execute_input":"2023-10-02T20:19:18.467339Z","iopub.status.idle":"2023-10-02T20:19:18.481323Z","shell.execute_reply.started":"2023-10-02T20:19:18.467298Z","shell.execute_reply":"2023-10-02T20:19:18.47996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the function to tranform the dates\nmonth_name_to_number(details_stadium_df, 8)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.483474Z","iopub.execute_input":"2023-10-02T20:19:18.484721Z","iopub.status.idle":"2023-10-02T20:19:18.52842Z","shell.execute_reply.started":"2023-10-02T20:19:18.484674Z","shell.execute_reply":"2023-10-02T20:19:18.527417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df[['Opening_Date','Record_Date', 'opening_date_cleaned']].head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.529707Z","iopub.execute_input":"2023-10-02T20:19:18.530009Z","iopub.status.idle":"2023-10-02T20:19:18.549457Z","shell.execute_reply.started":"2023-10-02T20:19:18.529984Z","shell.execute_reply":"2023-10-02T20:19:18.548132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Time to do the same with 'Record_Date' column**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.553036Z","iopub.execute_input":"2023-10-02T20:19:18.55381Z","iopub.status.idle":"2023-10-02T20:19:18.561492Z","shell.execute_reply.started":"2023-10-02T20:19:18.553776Z","shell.execute_reply":"2023-10-02T20:19:18.560118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a df with the 'Record_Date' column\nrec_date_df = pd.DataFrame(details_stadium_df['Record_Date'])\nrec_date_df['clean_rec_date'] = rec_date_df['Record_Date'].str.replace(r'\\([^)]*\\)', '', regex=True)   # 1- removing all '()' and everything inside\n\n# Looking at the stadium's Wiki page, both dates had the same record attendance,\n# so I decided to save the more recent one, which is November 2, 2010\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace('29 de maio[3] e ', '')\n\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace(r'\\[[^\\]]*\\]', '', regex=True) # 2- removing all '[]' and everything inside\nrec_date_df['clean_rec_date'] = rec_date_df['clean_rec_date'].str.replace('1º', '01')                    # 3- removing all '1º' and replacing for '01'","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.571351Z","iopub.execute_input":"2023-10-02T20:19:18.572545Z","iopub.status.idle":"2023-10-02T20:19:18.582965Z","shell.execute_reply.started":"2023-10-02T20:19:18.572509Z","shell.execute_reply":"2023-10-02T20:19:18.581857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"details_stadium_df['record_date_cleaned'] = rec_date_df['clean_rec_date']\ndetails_stadium_df[['Record_Date', 'record_date_cleaned']]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.593789Z","iopub.execute_input":"2023-10-02T20:19:18.594253Z","iopub.status.idle":"2023-10-02T20:19:18.614869Z","shell.execute_reply.started":"2023-10-02T20:19:18.594219Z","shell.execute_reply":"2023-10-02T20:19:18.613402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using the function to clean the date\nmonth_name_to_number(details_stadium_df, 9)\n\ndetails_stadium_df['record_date_cleaned'] = details_stadium_df['record_date_cleaned'].str.replace(' ', '-').str.replace('/', '-')\ndetails_stadium_df[['Record_Date','record_date_cleaned']].head(20)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.61691Z","iopub.execute_input":"2023-10-02T20:19:18.617239Z","iopub.status.idle":"2023-10-02T20:19:18.650858Z","shell.execute_reply.started":"2023-10-02T20:19:18.617213Z","shell.execute_reply":"2023-10-02T20:19:18.649379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Transforming the 'Record_Attendance' column**","metadata":{}},{"cell_type":"code","source":"# pd.options.display.max_rows = None\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.653829Z","iopub.execute_input":"2023-10-02T20:19:18.654699Z","iopub.status.idle":"2023-10-02T20:19:18.662985Z","shell.execute_reply.started":"2023-10-02T20:19:18.654655Z","shell.execute_reply":"2023-10-02T20:19:18.662142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a df with the copy of the 'Record_Attendance' column\nrec_attendance_df = pd.DataFrame(details_stadium_df['Record_Attendance'])\n\n# removing some words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['Record_Attendance'].str.replace('presentes', '')\\\n                                                                                  .str.replace('pagantes', '_').str.strip() # replaces a word for '_'\n\n# removing the words 'pessoas'\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('pessoas2', '')\\\n                                                                                     .str.replace('Pessoas', '')\\\n                                                                                     .str.replace('pessoas', ' ')\n\n#removing some more words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('torcedores', '')\\\n                                                                                     .str.replace('espectadores', '')\\\n                                                                                     .str.replace('lugares', '')\n# removing [] and everything inside\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)\n\n# removing more words\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('(não oficial)', '')\\\n                                                                                     .str.replace('(de acordo com a CBF)', '')\\\n                                                                                     .str.replace('(público total)', '')\n\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('.', '') # remove dots\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace('  ', '+') # replace double spaces for '+'\n\n# creates a dictionary with words and symbols i will remove or replace for oanother symbols\nreplace = {'pags': '', 'mil': '000', 'Mil':'', '\\n': '-', 'e': '', ',': '', '\\xa0': ''}\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].replace(replace, regex=True) # uses the dict created\n\n# replaces the () for '-'\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(r'[()]', '-', regex=True).str.strip()\n\n# replace some more symbols\nrec_attendance_df['clean_rec_attendance'] = rec_attendance_df['clean_rec_attendance'].str.replace(' ', '')\\\n                                                                                    .str.replace('+-', '-')\\\n                                                                                    .str.replace('_', '-')\\\n                                                                                    .str.replace('--', '-')\\\n                                                                                    .str.replace('+', '-')\\\n                                                                                    .str.replace('-', ' ')\\\n                                                                                    .str.strip()\n\n# gets only the max number of each line \nrec_attendance_df['clean_rec_attendance'] = [max(linha.split()) if isinstance(linha, str) else np.nan\n                                             for linha in rec_attendance_df['clean_rec_attendance']]\n ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.664811Z","iopub.execute_input":"2023-10-02T20:19:18.66553Z","iopub.status.idle":"2023-10-02T20:19:18.694415Z","shell.execute_reply.started":"2023-10-02T20:19:18.665487Z","shell.execute_reply":"2023-10-02T20:19:18.69316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add the cleaned column to the main df\ndetails_stadium_df['record_attendance_cleaned'] = rec_attendance_df['clean_rec_attendance']\ndetails_stadium_df[['Record_Attendance', 'record_attendance_cleaned']].head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:19:18.717883Z","iopub.execute_input":"2023-10-02T20:19:18.719235Z","iopub.status.idle":"2023-10-02T20:19:18.741828Z","shell.execute_reply.started":"2023-10-02T20:19:18.719186Z","shell.execute_reply":"2023-10-02T20:19:18.740369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4) Cleaning 'Stadium_Name' column**","metadata":{}},{"cell_type":"code","source":"# creates a new column in the main df and remove the word 'Sisbrace' and everything that comes after\ndetails_stadium_df['stadium_name_cleaned'] = details_stadium_df['Stadium_Name'].str.replace(r'Sisbrace.*', '', regex=True)\n\n# remove the [] and everything inside\ndetails_stadium_df['stadium_name_cleaned'] = details_stadium_df['stadium_name_cleaned'].str.replace(r'\\[[^\\]]*\\]', '', regex=True)\n\n# remove the () in this particular line\ndetails_stadium_df['stadium_name_cleaned'][27] = details_stadium_df['stadium_name_cleaned'][27].replace('(Manduzão)', 'Manduzão')\n\ndetails_stadium_df[['Stadium_Name', 'stadium_name_cleaned']].head(15)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T20:51:38.773361Z","iopub.execute_input":"2023-10-02T20:51:38.773713Z","iopub.status.idle":"2023-10-02T20:51:38.790592Z","shell.execute_reply.started":"2023-10-02T20:51:38.773687Z","shell.execute_reply":"2023-10-02T20:51:38.788881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5) Cleaning 'Official_Name' column**","metadata":{}}]}